{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os \n",
    "import time \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1222\n",
      "23778\n"
     ]
    }
   ],
   "source": [
    "# Split data from folder \n",
    "data_dir=\"data\"\n",
    "\n",
    "classes = ['positiveReviews', 'negativeReviews']\n",
    "\n",
    "train_data=[]\n",
    "train_labels=[]\n",
    "test_data=[]\n",
    "test_labels=[]\n",
    "\n",
    "for curr_class in classes:\n",
    "    dirname=os.path.join(data_dir,curr_class)\n",
    "    for fname in os.listdir(dirname):\n",
    "        with open(os.path.join(dirname,fname),\"r\") as f:\n",
    "                content=f.read()\n",
    "                \n",
    "                if fname.startswith(\"12\"):\n",
    "                    test_data.append(content)\n",
    "                    test_labels.append(curr_class)\n",
    "                else:\n",
    "                    train_data.append(content)\n",
    "                    train_labels.append(curr_class)\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf\n",
    "\n",
    "Tf-idf stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
    "\n",
    "\n",
    "**TF**: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "\n",
    "**TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)**\n",
    "\n",
    "**IDF**: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "**IDF(t) = log_e(Total number of documents / Number of documents with term t in it)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer=TfidfVectorizer(min_df=5,\n",
    "                          max_df=0.8,\n",
    "                          sublinear_tf=True,\n",
    "                          use_idf=True)\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "test_vectors = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.07790818, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make ml models\n",
    "clf_nb=MultinomialNB()\n",
    "clf_nb.fit(train_vectors,train_labels)\n",
    "prediction_nb=clf_nb.predict(test_vectors)\n",
    "\n",
    "clf_rf=ensemble.RandomForestClassifier()\n",
    "clf_rf.fit(train_vectors,train_labels)\n",
    "prediction_rf=clf_rf.predict(test_vectors)\n",
    "\n",
    "\n",
    "clf_lr=linear_model.LogisticRegression()\n",
    "clf_lr.fit(train_vectors,train_labels)\n",
    "prediction_lr=clf_lr.predict(test_vectors)\n",
    "\n",
    "\n",
    "clf_svm=svm.SVC()\n",
    "clf_svm.fit(train_vectors,train_labels)\n",
    "prediction_svm=clf_svm.predict(test_vectors)\n",
    "\n",
    "\n",
    "clf_svm_l=svm.LinearSVC()\n",
    "clf_svm_l.fit(train_vectors,train_labels)\n",
    "prediction_svm_l=clf_svm_l.predict(test_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Road Map**\n",
    "\n",
    "**True Positive (TP)**: The true label of the given instance is positive, and the classifier also predicts it as a positive\n",
    "\n",
    "**True Negative (TN)**: The true label is negative, and the classifier also predicts a negative\n",
    "\n",
    "**False Positive (FP)**: The true label is negative, but the classifier incorrectly predicts it as positive\n",
    "\n",
    "**False Negative (FN)**: The true label is positive, but the classifier incorrectly predicts it as negative\n",
    "\n",
    "![title](images/1.png)\n",
    "\n",
    "\n",
    "**Precision**: Precision is the ability of the classifier to assign a\n",
    "positive class label for samples that originally belong to a positive class label\n",
    "**Precision=TP/TP+FP**\n",
    "\n",
    "**Recall** :Recall is the ability of the classifier to find all the positive\n",
    "samples. \n",
    "**Recall=TP/TP+FN**\n",
    "\n",
    "**F1-Score**: F1-score is the harmonic means of precision and recall.\n",
    "**F1 = 2 * (precision * recall) / (precision + recall)**\n",
    "\n",
    "a useful link : https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Results for NaiveBayes\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "negativeReviews       0.79      0.87      0.82       611\n",
      "positiveReviews       0.85      0.77      0.81       611\n",
      "\n",
      "      micro avg       0.82      0.82      0.82      1222\n",
      "      macro avg       0.82      0.82      0.82      1222\n",
      "   weighted avg       0.82      0.82      0.82      1222\n",
      "\n",
      "~ Accuracy scoer of Multinomial NavieBayes algorithm --->0.8158756137479541\n",
      "\n",
      "\n",
      "~ Reviews Prediction\n",
      "\n",
      "Test label is       ----> positiveReviews\n",
      "Prediction label is ----> negativeReviews\n",
      "\n",
      "*** Movies Review *** \n",
      "This movie scared the crap out of me! I have to admit that I spent most of the film watching through my fingers but what I saw was really scary. I screamed out loud two or three times during the show.<br /><br />Film-making-wise my favorite aspects were the sound and photography. The sound was particularly great and the setting was really creepy beautiful. I read somewhere that it's some weird husband and wife team that made it. For some reason that makes this even stranger for me. <br /><br />If you enjoy the jumps and jitters of scary movies than this one is for you! Very suspenseful and a great movie to rent with a bunch of friends who love to watch movies curled up on a sofa screaming like little girls!\n"
     ]
    }
   ],
   "source": [
    "print(\"~ Results for NaiveBayes\\n\")\n",
    "print(classification_report(test_labels,prediction_nb))\n",
    "print(\"~ Accuracy scoer of Multinomial NavieBayes algorithm --->\" +str(accuracy_score(test_labels,\n",
    "                                                                                   prediction_nb)))\n",
    "i=1\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"~ Reviews Prediction\")\n",
    "print(\"\\nTest label is       ----> \"+test_labels[i])\n",
    "print(\"Prediction label is ----> \"+prediction_nb[i])\n",
    "print(\"\\n*** Movies Review *** \\n\"+test_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That is interesting sample. We can measure of algorithn performance according to this sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69652871 0.30347129]]\n",
      "['negativeReviews']\n"
     ]
    }
   ],
   "source": [
    "print(clf_nb.predict_proba(test_vectors[1]))\n",
    "print(clf_nb.predict(test_vectors[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Results for Logistic Regression\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "negativeReviews       0.86      0.88      0.87       611\n",
      "positiveReviews       0.88      0.86      0.87       611\n",
      "\n",
      "      micro avg       0.87      0.87      0.87      1222\n",
      "      macro avg       0.87      0.87      0.87      1222\n",
      "   weighted avg       0.87      0.87      0.87      1222\n",
      "\n",
      "~ Accuracy scoer of Multinomial Logistic Regression algorithm --->0.8707037643207856\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "prediction=prediction_lr\n",
    "alg=\"Logistic Regression\"\n",
    "print(\"~ Results for {}\\n\".format(alg))\n",
    "print(classification_report(test_labels,prediction))\n",
    "print(\"~ Accuracy scoer of Multinomial {} algorithm --->\".format(alg) +str(accuracy_score(test_labels,\n",
    "                                                                                   prediction)))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"~ Reviews Prediction\")\n",
    "print(\"\\nTest label is       ----> \"+test_labels[i])\n",
    "print(\"Prediction label is ----> \"+prediction[i])\n",
    "print(\"\\n*** Movies Review *** \\n\"+test_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wow ! This is really impressive performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21991114 0.78008886]]\n",
      "['positiveReviews']\n"
     ]
    }
   ],
   "source": [
    "print(clf_lr.predict_proba(test_vectors[1]))\n",
    "print(clf_lr.predict(test_vectors[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which samples are wrongs ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find wrong predictions\n",
    "proba_lr=clf_lr.predict_proba(test_vectors)\n",
    "wrong_list=[]\n",
    "for i in range(len(prediction_lr)):\n",
    "    if prediction_lr[i]!=test_labels[i]:\n",
    "        pr=prediction_lr[i]\n",
    "        ts=test_labels[i]\n",
    "        t_m=test_data[i]\n",
    "        t_p=proba_lr[i]\n",
    "        \n",
    "        wrong_list.append([ts,pr,t_p,t_m,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positiveReviews',\n",
       " 'negativeReviews',\n",
       " array([0.65987012, 0.34012988]),\n",
       " '\"A Guy Thing\" may not be a classic, but it sure is a good, funny comedy. The plot focuses on Paul (Jason Lee), who wakes up the morning after his bachelor party with no memory and Becky (Julia Stiles) lying naked in his bed. Before he can figure out what happened, he rushes Becky out of his apartment because his fiance Karen (Selma Blair) is coming. After that, as you could imagine, chaos ensues.<br /><br />Almost every single scene in \"A Guy Thing\" delivers loud laughs. The funniest moments come from when Paul imagines what could happen if he tells Karen. Selma Blair is a truly talented comedian, and the worst thing about this film is that she goes underused. Although, she turns out to be more funny than Stiles\\' character, who actually isn\\'t that interesting. Of course, not every comedy is perfect.<br /><br />As I said, \"A Guy Thing\" is no classic, but it\\'s not bad either, 7/10.',\n",
       " 27]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test label is         ----> positiveReviews\n",
      "Prediction label is   ----> negativeReviews\n",
      "Probability is        ----> [0.73272414 0.26727586]\n",
      "\n",
      "*** Movies Review *** \n",
      "Good western filmed in the rocky Arizona wilds. Lots of tough guys throughout; Cobern's character seemed to rock back and forth between a raging psycho and a laid back type. Several holes appeared in the picture, but not enough to offset it being exciting and worth seeing. One really dumb scene shows Heston emptying .45 cases of their powder and collecting it in a sack for the purpose of starting a fire. A. To gather that much gunpowder he would have needed a pack mule to carry the ammo. B. The grass was obviously dry: why not just drop a match on it and let 'er rip?\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "# Show a wrong  prediction\n",
    "i=34\n",
    "print(\"Test label is         ----> \"+wrong_list[i][0])\n",
    "print(\"Prediction label is   ----> \"+wrong_list[i][1])\n",
    "print(\"Probability is        ---->\",wrong_list[i][2])\n",
    "print(\"\\n*** Movies Review *** \\n\"+wrong_list[i][3])\n",
    "print(wrong_list[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negativeReviews']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.56145329, 0.43854671]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf_lr.predict(vectorizer.transform([\"Completely is lacking in good taste,good service\"])))\n",
    "clf_lr.predict_proba(vectorizer.transform([\"Completely is lacking in good taste,good service\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Results for Random Forrest\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "negativeReviews       0.70      0.81      0.75       611\n",
      "positiveReviews       0.77      0.66      0.71       611\n",
      "\n",
      "      micro avg       0.73      0.73      0.73      1222\n",
      "      macro avg       0.74      0.73      0.73      1222\n",
      "   weighted avg       0.74      0.73      0.73      1222\n",
      "\n",
      "~ Accuracy scoer of Multinomial Random Forrest algorithm --->0.7332242225859247\n",
      "\n",
      "\n",
      "~ Reviews Prediction\n",
      "\n",
      "Test label is       ----> positiveReviews\n",
      "Prediction label is ----> negativeReviews\n",
      "\n",
      "*** Movies Review *** \n",
      "This movie scared the crap out of me! I have to admit that I spent most of the film watching through my fingers but what I saw was really scary. I screamed out loud two or three times during the show.<br /><br />Film-making-wise my favorite aspects were the sound and photography. The sound was particularly great and the setting was really creepy beautiful. I read somewhere that it's some weird husband and wife team that made it. For some reason that makes this even stranger for me. <br /><br />If you enjoy the jumps and jitters of scary movies than this one is for you! Very suspenseful and a great movie to rent with a bunch of friends who love to watch movies curled up on a sofa screaming like little girls!\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "prediction=prediction_rf\n",
    "alg=\"Random Forest\"\n",
    "print(\"~ Results for {}\\n\".format(alg))\n",
    "print(classification_report(test_labels,prediction))\n",
    "print(\"~ Accuracy scoer of Multinomial {} algorithm --->\".format(alg) +str(accuracy_score(test_labels,\n",
    "                                                                                   prediction)))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"~ Reviews Prediction\")\n",
    "print(\"\\nTest label is       ----> \"+test_labels[i])\n",
    "print(\"Prediction label is ----> \"+prediction[i])\n",
    "print(\"\\n*** Movies Review *** \\n\"+test_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Results for Support Vector Machine lineaer\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "negativeReviews       0.82      0.86      0.84       611\n",
      "positiveReviews       0.85      0.81      0.83       611\n",
      "\n",
      "      micro avg       0.84      0.84      0.84      1222\n",
      "      macro avg       0.84      0.84      0.84      1222\n",
      "   weighted avg       0.84      0.84      0.84      1222\n",
      "\n",
      "~ Accuracy scoer of Multinomial Support Vector Machine lineaer algorithm --->0.8363338788870703\n",
      "\n",
      "\n",
      "~ Reviews Prediction\n",
      "\n",
      "Test label is       ----> positiveReviews\n",
      "Prediction label is ----> positiveReviews\n",
      "\n",
      "*** Movies Review *** \n",
      "This movie scared the crap out of me! I have to admit that I spent most of the film watching through my fingers but what I saw was really scary. I screamed out loud two or three times during the show.<br /><br />Film-making-wise my favorite aspects were the sound and photography. The sound was particularly great and the setting was really creepy beautiful. I read somewhere that it's some weird husband and wife team that made it. For some reason that makes this even stranger for me. <br /><br />If you enjoy the jumps and jitters of scary movies than this one is for you! Very suspenseful and a great movie to rent with a bunch of friends who love to watch movies curled up on a sofa screaming like little girls!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=1\n",
    "prediction=prediction_svm_l\n",
    "alg=\"Support Vector Machine lineaer\"\n",
    "print(\"~ Results for {}\\n\".format(alg))\n",
    "print(classification_report(test_labels,prediction))\n",
    "print(\"~ Accuracy scoer of Multinomial {} algorithm --->\".format(alg) +str(accuracy_score(test_labels,\n",
    "                                                                                   prediction)))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"~ Reviews Prediction\")\n",
    "print(\"\\nTest label is       ----> \"+test_labels[i])\n",
    "print(\"Prediction label is ----> \"+prediction[i])\n",
    "print(\"\\n*** Movies Review *** \\n\"+test_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimensional Reduction with SVD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=TruncatedSVD(n_components=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train=transform.fit_transform(train_vectors)\n",
    "transform_test=transform.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.fit(transform_train,train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855973813420622"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.score(transform_test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
